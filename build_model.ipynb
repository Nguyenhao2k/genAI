{"cells":[{"source":"# Setup","metadata":{},"id":"ecc2dc30-f8ad-498c-b6ad-c9855139ec0a","cell_type":"markdown"},{"source":"!pip install torchmultimodal-nightly","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false},"executionCancelledAt":null,"executionTime":9780,"lastExecutedAt":1701749659327,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install torchmultimodal-nightly","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"id":"a78cffb0-d82e-4c2f-ab65-f4b04d2908bf","cell_type":"code","execution_count":4,"outputs":[]},{"source":"import torch\nimport torchvision\nimport torchvision.transforms.functional as F\n\nfrom torch import nn\nfrom tqdm import tqdm\nfrom torchmultimodal.diffusion_labs.modules.adapters.cfguidance import CFGuidance\nfrom torchmultimodal.diffusion_labs.modules.losses.diffusion_hybrid_loss import DiffusionHybridLoss\nfrom torchmultimodal.diffusion_labs.samplers.ddpm import DDPModule\nfrom torchmultimodal.diffusion_labs.predictors.noise_predictor import NoisePredictor\nfrom torchmultimodal.diffusion_labs.schedules.discrete_gaussian_schedule import linear_beta_schedule, DiscreteGaussianSchedule\nfrom torchmultimodal.diffusion_labs.transforms.diffusion_transform import RandomDiffusionSteps\nfrom torchmultimodal.diffusion_labs.utils.common import DiffusionOutput","metadata":{"executionCancelledAt":null,"executionTime":953,"lastExecutedAt":1701751587782,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import torch\nimport torchvision\nimport torchvision.transforms.functional as F\n\nfrom torch import nn\nfrom tqdm import tqdm\n#from torchmultimodal.diffusion_labs.models.adm_unet.adm import adm_unet\nfrom torchmultimodal.diffusion_labs.modules.adapters.cfguidance import CFGuidance\nfrom torchmultimodal.diffusion_labs.modules.losses.diffusion_hybrid_loss import DiffusionHybridLoss\nfrom torchmultimodal.diffusion_labs.samplers.ddpm import DDPModule\nfrom torchmultimodal.diffusion_labs.predictors.noise_predictor import NoisePredictor\nfrom torchmultimodal.diffusion_labs.schedules.discrete_gaussian_schedule import linear_beta_schedule, DiscreteGaussianSchedule\nfrom torchmultimodal.diffusion_labs.transforms.diffusion_transform import RandomDiffusionSteps\nfrom torchmultimodal.diffusion_labs.utils.common import DiffusionOutput"},"id":"1a118cdc-98cc-4d4f-9381-bb2b735844d3","cell_type":"code","execution_count":1,"outputs":[]},{"source":"# Schedule","metadata":{},"id":"a5d37ad0-fa4f-464d-bcfc-ca5b38981c66","cell_type":"markdown"},{"source":"schedule = DiscreteGaussianSchedule(linear_beta_schedule(1000))","metadata":{},"id":"11583926-c1e6-4b1c-9573-49d625487e88","cell_type":"code","execution_count":null,"outputs":[]},{"source":"# Predictor","metadata":{},"id":"df881f59-2ee1-4be8-9a7b-58d90933aa12","cell_type":"markdown"},{"source":"predictor = NoisePredictor(schedule, lambda x: torch.clamp(x, -1, 1))","metadata":{},"id":"4b5f1202-287c-4fa9-89b3-dbc280e671e3","cell_type":"code","execution_count":null,"outputs":[]},{"source":"# U-Net","metadata":{},"id":"9d3a2e7d-68f3-4ef8-b852-a661cb6cdd70","cell_type":"markdown"},{"source":"```\nfrom torchmultimodal.diffusion_labs.models.adm_unet.adm import adm_unet\n\nunet = adm_unet(\n    time_embed_dim=32,\n    embed_dim=32,\n    embed_name=\"context\",\n    predict_variance_value=True,\n    image_channels=1,\n)\n```","metadata":{},"id":"bf871c74-dbb2-40fa-ba03-9c7dec27fc69","cell_type":"markdown"},{"source":"class DownBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, cond_channels):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(in_channels + cond_channels, out_channels, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n        self.pooling = nn.AvgPool2d(kernel_size=2, stride=2)\n\n    def forward(self, x, c):\n        _, _, w, h = x.size()\n        c = c.expand(-1, -1, w, h)\n        x = self.block(torch.cat([x, c], 1))\n        x_small = self.pooling(x)\n        return x, x_small\n\nclass UpBlock(nn.Module):\n    def __init__(self, inp, out):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(inp*2, out, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(out, out, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n        self.upsample = nn.Upsample(scale_factor=2)\n\n    def forward(self, x, x_small):\n        x_big = self.upsample(x_small)\n        x = torch.cat((x_big, x), dim=1)\n        x = self.block(x)\n        return x\n\nclass UNet(nn.Module):\n    def __init__(self, time_size=32, digit_size=32, steps=1000):\n        super().__init__()\n        cond_size = time_size + digit_size\n        self.conv = nn.Conv2d(1, 128, kernel_size=3, padding=1)\n        self.down = nn.ModuleList([DownBlock(128, 256, cond_size), DownBlock(256, 512, cond_size)])\n        self.bottleneck = DownBlock(512, 512, cond_size)\n        self.up = nn.ModuleList([UpBlock(512, 256), UpBlock(256, 128)])\n\n        self.variance = nn.Conv2d(128, 1, kernel_size=3, padding=1)\n        self.prediction = nn.Conv2d(128, 1, kernel_size=3, padding=1)\n        self.time_projection = nn.Embedding(steps, time_size)\n\n    def forward(self, x, t, conditional_inputs):\n        b, c, h, w = x.shape\n        timestep = self.time_projection(t).view(b, -1, 1, 1)\n        condition = conditional_inputs[\"context\"].view(b, -1, 1, 1)\n        condition = torch.cat([timestep, condition], dim=1)\n\n        x = self.conv(x)\n        self.outs = []\n        for block in self.down:\n            out, x = block(x, condition)\n            self.outs.append(out)\n        x, _ = self.bottleneck(x, condition)\n        for block in self.up:\n            x = block(self.outs.pop(), x)\n        v = self.variance(x)\n        p = self.prediction(x)\n        return DiffusionOutput(p, v)","metadata":{"executionCancelledAt":null,"executionTime":60,"lastExecutedAt":1701751617399,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"class DownBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, cond_channels):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(in_channels + cond_channels, out_channels, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n        self.pooling = nn.AvgPool2d(kernel_size=2, stride=2)\n\n    def forward(self, x, c):\n        _, _, w, h = x.size()\n        c = c.expand(-1, -1, w, h)\n        x = self.block(torch.cat([x, c], 1))\n        x_small = self.pooling(x)\n        return x, x_small\n\nclass UpBlock(nn.Module):\n    def __init__(self, inp, out):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(inp*2, out, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(out, out, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n        self.upsample = nn.Upsample(scale_factor=2)\n\n    def forward(self, x, x_small):\n        x_big = self.upsample(x_small)\n        x = torch.cat((x_big, x), dim=1)\n        x = self.block(x)\n        return x\n\nclass UNet(nn.Module):\n    def __init__(self, time_size=32, digit_size=32, steps=1000):\n        super().__init__()\n        cond_size = time_size + digit_size\n        self.conv = nn.Conv2d(1, 128, kernel_size=3, padding=1)\n        self.down = nn.ModuleList([DownBlock(128, 256, cond_size), DownBlock(256, 512, cond_size)])\n        self.bottleneck = DownBlock(512, 512, cond_size)\n        self.up = nn.ModuleList([UpBlock(512, 256), UpBlock(256, 128)])\n\n        self.variance = nn.Conv2d(128, 1, kernel_size=3, padding=1)\n        self.prediction = nn.Conv2d(128, 1, kernel_size=3, padding=1)\n        self.time_projection = nn.Embedding(steps, time_size)\n\n    def forward(self, x, t, conditional_inputs):\n        b, c, h, w = x.shape\n        timestep = self.time_projection(t).view(b, -1, 1, 1)\n        condition = conditional_inputs[\"context\"].view(b, -1, 1, 1)\n        condition = torch.cat([timestep, condition], dim=1)\n\n        x = self.conv(x)\n        self.outs = []\n        for block in self.down:\n            out, x = block(x, condition)\n            self.outs.append(out)\n        x, _ = self.bottleneck(x, condition)\n        for block in self.up:\n            x = block(self.outs.pop(), x)\n        v = self.variance(x)\n        p = self.prediction(x)\n        return DiffusionOutput(p, v)"},"id":"31d74945-023a-4a2f-8dc5-592b6a146f13","cell_type":"code","execution_count":2,"outputs":[]},{"source":"# Diffusion Model","metadata":{},"id":"73db444e-04bc-4e8c-ad4b-996796553067","cell_type":"markdown"},{"source":"unet = UNet(time_size=32, digit_size=32)\nunet = CFGuidance(unet, {\"context\": 32}, guidance=2.0)","metadata":{},"id":"74c34e46-b89e-4f97-9562-98f397fc521b","cell_type":"code","execution_count":null,"outputs":[]},{"source":"eval_steps = torch.linspace(0, 999, 250, dtype=torch.long)\nmodel = DDPModule(unet, schedule, predictor, eval_steps)","metadata":{"executionCancelledAt":null,"executionTime":122,"lastExecutedAt":1701751630882,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"model = UNet(time_size=32, digit_size=32)\nmodel = CFGuidance(model, {\"context\": 32}, guidance=2.0)\nmodel = DDPModule(model, schedule, predictor, eval_steps)"},"id":"c5315b1c-c803-4a42-9d7e-0ac105754c1d","cell_type":"code","execution_count":6,"outputs":[]},{"source":"encoder = nn.Embedding(10, 32)","metadata":{},"id":"c795c9ad-2f0a-4530-9049-1334959b9669","cell_type":"code","execution_count":null,"outputs":[]},{"source":"# Data","metadata":{},"id":"1b4aedbc-cf0e-46a8-a086-9015123475e5","cell_type":"markdown"},{"source":"from torchvision.transforms import Compose, Resize, ToTensor, Lambda\n\ndiffusion_transform = RandomDiffusionSteps(schedule, batched=False)\ntransform = Compose([Resize(32),\n                     ToTensor(),\n                     Lambda(lambda x: 2*x - 1),\n                     Lambda(lambda x: diffusion_transform({\"x\": x}))])","metadata":{"executionCancelledAt":null,"executionTime":12,"lastExecutedAt":1701751636793,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from torchvision.transforms import Compose, Resize, ToTensor, Lambda\n\ndiffusion_transform = RandomDiffusionSteps(schedule, batched=False)\ntransform = Compose([Resize(32),\n                     ToTensor(),\n                     Lambda(lambda x: 2*x - 1),\n                     Lambda(lambda x: diffusion_transform({\"x\": x}))])"},"id":"edc1cdac-c45e-4a8f-b4f2-1cb14415616d","cell_type":"code","execution_count":8,"outputs":[]},{"source":"from torchvision.datasets import FashionMNIST\nfrom torch.utils.data import DataLoader\n\ntrain_dataset = FashionMNIST(\"fashion_mnist\", train=True, download=True, transform=transform)\ntrain_dataloader = DataLoader(train_dataset, batch_size=192, shuffle=True, num_workers=2, pin_memory=True)","metadata":{"executionCancelledAt":null,"executionTime":205,"lastExecutedAt":1701751638894,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from torchvision.datasets import FashionMNIST\nfrom torch.utils.data import DataLoader\n\ntrain_dataset = FashionMNIST(\"fashion_mnist\", train=True, download=True, transform=transform)\ntrain_dataloader = DataLoader(train_dataset, batch_size=192, shuffle=True, num_workers=2, pin_memory=True) #192","outputsMetadata":{"0":{"height":77,"type":"stream"},"2":{"height":117,"type":"stream"},"4":{"height":117,"type":"stream"},"6":{"height":117,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"id":"49067ae8-342c-488a-9cf1-9d4381d7adb1","cell_type":"code","execution_count":9,"outputs":[]},{"source":"# Train","metadata":{},"id":"137eb307-5298-4ca7-a7fe-241ec87f28f2","cell_type":"markdown"},{"source":"epochs = 25\n\ndevice = \"cpu\"\nencoder.to(device)\nmodel.to(device)\n\noptimizer = torch.optim.AdamW(\n    [{\"params\": encoder.parameters()}, {\"params\": model.parameters()}], lr=0.0001\n)\nh_loss = DiffusionHybridLoss(schedule)\n\nencoder.train()\nmodel.train()\nfor e in range(epochs):\n\tfor sample in (pbar := tqdm(train_dataloader)):\n\t\tx, c = sample\n\t\tx0, xt, noise, t, c = x[\"x\"].to(device), x[\"xt\"].to(device), x[\"noise\"].to(device), x[\"t\"].to(device), c.to(device)\n\t\toptimizer.zero_grad()\n\n\t\tc = encoder(c)\n\t\tout = model(xt, t, {\"context\": c})\n\t\tloss = h_loss(out.prediction, noise, out.mean, out.log_variance, x0, xt, t)\n\n\t\tloss.backward()\n\t\toptimizer.step()\n\n\t\tpbar.set_description(f'{e+1}| Loss: {loss.item()}')","metadata":{"executionCancelledAt":null,"executionTime":268432,"lastExecutedAt":1701751937147,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"epochs = 25\n\ndevice = \"cpu\"\nencoder.to(device)\nmodel.to(device)\n\noptimizer = torch.optim.AdamW(\n    [{\"params\": encoder.parameters()}, {\"params\": model.parameters()}], lr=0.0001 # .0001\n)\nh_loss = DiffusionHybridLoss(schedule)\n\n# lr_scheduler = get_cosine_schedule_with_warmup(\n#     optimizer, 1 * len(train_dataloader), 100 * len(train_dataloader)\n# ) # added for mlp\n#scaler = torch.cuda.amp.GradScaler()\n\nencoder.train()\nmodel.train()\nfor e in range(epochs):\n\tfor sample in (pbar := tqdm(train_dataloader)):\n\t\tx, c = sample\n\t\tx0, xt, noise, t, d = x[\"x\"].to(device), x[\"xt\"].to(device), x[\"noise\"].to(device), x[\"t\"].to(device), c.to(device)\n\t\toptimizer.zero_grad()\n\n\t\t#with torch.autocast(device.split(\":\")[0]):\n\t\tc = encoder(c)\n\t\tout = model(xt, t, {\"context\": c})\n\t\tloss = h_loss(out.prediction, noise, out.mean, out.log_variance, x0, xt, t)\n\n\t\tloss.backward()\n\t\toptimizer.step()\n\t\t# scaler.scale(loss).backward()\n\t\t# scaler.step(optimizer)\n\t\t# scaler.update()\n\n\t\t#lr_scheduler.step()\n\t\tpbar.set_description(f'{e+1}| Loss: {loss.item()}')","outputsMetadata":{"0":{"height":37,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"id":"a009996c-3cbf-4d35-b1bd-79d9ac0571a6","cell_type":"code","execution_count":null,"outputs":[]},{"source":"# Generate","metadata":{},"id":"43df1f90-d76e-4ca7-916c-983b33e8c856","cell_type":"markdown"},{"source":"def fashion_encoder(name, num=1):\n    fashion_dict = {\"t-shirt\": 0, \"pants\": 1, \"sweater\": 2, \"dress\": 3, \"coat\": 4, \n                    \"sandal\": 5, \"shirt\": 6, \"sneaker\": 7, \"purse\": 8, \"boot\": 9}\n    idx = torch.as_tensor([fashion_dict[name] for _ in range(num)]).to(device)\n\n    encoder.eval()\n    with torch.no_grad():\n        embed = encoder(idx)\n    return embed","metadata":{"executionCancelledAt":null,"executionTime":12,"lastExecutedAt":1701752167796,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def fashion_encoder(name, num=1):\n    fashion_dict = {\"t-shirt\": 0, \"pants\": 1, \"sweater\": 2, \"dress\": 3, \"coat\": 4, \"sandal\": 5, \"shirt\": 6, \"sneaker\": 7, \"purse\": 8, \"boot\": 9}\n    idx = torch.as_tensor([fashion_dict[name] for _ in range(num)]).to(device)\n\n    encoder.eval()\n    with torch.no_grad():\n        embed = encoder(idx)\n    return embed"},"id":"a8b7957c-49ef-4877-9670-1a4fa149c561","cell_type":"code","execution_count":11,"outputs":[]},{"source":"model.eval()\n\nc = fashion_encoder(\"boot\", 9)\nnoise = torch.randn(size=(9,1,32,32)).to(device)\n\nwith torch.no_grad():\n    imgs = model(noise, conditional_inputs={\"context\": c})\n\nimg_grid = torchvision.utils.make_grid(imgs, 3)\nimg = F.to_pil_image((img_grid + 1) / 2)\nimg.resize((288, 288))","metadata":{"executionCancelledAt":null,"executionTime":280491,"lastExecutedAt":1701752585857,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"model.eval()\n\nc = fashion_encoder(\"boot\", 9)\nnoise = torch.randn(size=(9,1,32,32)).to(device)\n\nwith torch.no_grad():\n    imgs = model(noise, conditional_inputs={\"context\": c})\n\nimg_grid = torchvision.utils.make_grid(imgs, 3)\nimg = F.to_pil_image((img_grid + 1) / 2)\nimg.resize((288, 288))"},"id":"74bd6de9-6d0a-4eee-88a8-a9f78f37a264","cell_type":"code","execution_count":15,"outputs":[]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}